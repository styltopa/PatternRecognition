{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylianos Topalidis\n",
    "# AEM: 9613\n",
    "# email: styltopa@ece.auth.gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import pi, log \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 Estimation of theta parameters (theta_1(hat) and theta_2(hat))\n",
    "\n",
    "# x1: the values of indicator x for D1 \n",
    "x1 = np.array([2.8,-0.4,-0.8, 2.3,-0.3, 3.6, 4.1])\n",
    "x2 = np.array([-4.5, -3.4, -3.1, -3.0, -2.3])\n",
    "thetaStart = -10\n",
    "thetaStop = 10\n",
    "thetaStep = 0.1\n",
    "# the various theta for which we compute the pdf\n",
    "thetaRange = np.arange(thetaStart, thetaStop, thetaStep)\n",
    "\n",
    "# xSpace: has the same x in each column\n",
    "# thetaSpace: has the same theta in each row\n",
    "# each row has the likelihood values for a single theta\n",
    "x1Space, theta1Space = np.meshgrid(x1, thetaRange)\n",
    "x2Space, theta2Space = np.meshgrid(x2, thetaRange)\n",
    "\n",
    "# x1Space, thetaSpace, p1 are all of dimensions: len(thetaRange) x len(x1) \n",
    "# Accordingly for x2Space, thetaSpace, p2\n",
    "p1 = np.empty((x1Space.shape))     # same as p1 = np.empty((theta1Space.shape))     \n",
    "p1 = (1/pi)*(1/(1+np.power((x1Space-theta1Space), 2)))\n",
    "\n",
    "p2 = np.empty((x2Space.shape))     # same as p2 = np.empty((theta2Space.shape))     \n",
    "p2 = (1/pi)*(1/(1+np.power((x2Space-theta2Space), 2)))\n",
    "\n",
    "\n",
    "# pDGivenTheta1: the product of all probability density functions for all data x for \n",
    "# a specific theta. In other words, it is the product of all elements of a column\n",
    "# multiply.reduce(arr, 0) returns the array containing the product of the\n",
    "# elements of arr over dimension 1 (product of elements of each row).\n",
    "# Same goes for the pDGivenTheta2\n",
    "pDGivenTheta1 = np.multiply.reduce(p1, 1)\n",
    "pDGivenTheta2 = np.multiply.reduce(p2, 1)\n",
    "\n",
    "logPDTheta1 = np.log(pDGivenTheta1)\n",
    "logPDTheta2 = np.log(pDGivenTheta2)\n",
    "\n",
    "\n",
    "fig, ax0 = plt.subplots(1, 1)\n",
    "ax0.plot(thetaRange, logPDTheta1, label=r'p($D_1\\vert$$\\theta$)')\n",
    "ax0.plot(thetaRange, logPDTheta2, label=r'p($D_2\\vert$$\\theta$)')\n",
    "ax0.legend()\n",
    "ax0.set_xlabel(r'$\\theta$')\n",
    "ax0.set_xlabel(r'$\\theta$')\n",
    "ax0.set_title(r'Likelihood probability functions for datasets '\\\n",
    "    r'$D_1$ and $D_2$')\n",
    "\n",
    "\n",
    "# Find the exact theta giving the maximum logpDTheta\n",
    "# Since there are two maxima, it is better that we estimate the theta parameter \n",
    "# through the largest of the two.\n",
    "\n",
    "# theta_1(hat)\n",
    "print('Max value of log pdf given theta_1:', np.max(logPDTheta1))\n",
    "maxLogPDThetaIndexMat = np.where(logPDTheta1 == np.max(logPDTheta1))\n",
    "\n",
    "# Index corresponding to the maximum likelihood\n",
    "maxLogPDTheta1Index = maxLogPDThetaIndexMat[0][0]\n",
    "\n",
    "# theta1 value estimation (rounded in the last 3 decimals)\n",
    "theta1Estimate = round(thetaRange[maxLogPDTheta1Index], 3)\n",
    "print('theta_1(hat):', theta1Estimate)\n",
    "\n",
    "# theta_2(hat)\n",
    "print('Max value of log pdf given theta_2:', np.max(logPDTheta2))\n",
    "maxLogPDThetaIndexMat = np.where(logPDTheta2 == np.max(logPDTheta2))\n",
    "\n",
    "# Index corresponding to the maximum likelihood\n",
    "maxLogPDTheta2Index = maxLogPDThetaIndexMat[0][0]\n",
    "\n",
    "# theta2 value estimation (rounded in the last 3 decimals)\n",
    "theta2Estimate = round(thetaRange[maxLogPDTheta2Index], 3)\n",
    "print('theta_2(hat):', theta2Estimate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminant function g(x)\n",
    "xStart = -10\n",
    "xStop = 10\n",
    "xStep = 0.1\n",
    "xRange = np.arange(xStart,xStop, xStep)\n",
    "\n",
    "pXGivenTheta1Range = (1/pi)*(1/(1+np.power((xRange-theta1Estimate), 2)))\n",
    "pXGivenTheta2Range = (1/pi)*(1/(1+np.power((xRange-theta2Estimate), 2)))\n",
    "# the apriori probabilities are given by the relative frequency \n",
    "# of the cases of each class (omega1: not stressed, omega2: stressed)\n",
    "aPriori1 = len(x1)/(len(x1)+len(x2))\n",
    "aPriori2 = len(x2)/(len(x1)+len(x2))\n",
    "\n",
    "# the discrinant function calculated over a range of x (xRange)\n",
    "gX = np.log(pXGivenTheta1Range) - np.log(pXGivenTheta2Range) + aPriori1 - aPriori2\n",
    "\n",
    "# pdfs calculated on the x1 and x2\n",
    "pXGivenTheta1OnX1= (1/pi)*(1/(1+np.power((x1-theta1Estimate), 2)))\n",
    "pXGivenTheta2OnX2 = (1/pi)*(1/(1+np.power((x2-theta2Estimate), 2)))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x1, np.zeros_like(x1), s = 100, c=\"green\", alpha=0.5, marker='o',\n",
    "           label = r'Class $\\omega_1$: Not stressed')\n",
    "ax.scatter(x2, np.zeros_like(x2), s = 100, c=\"red\", alpha=0.5, marker='o',\n",
    "           label = r'Class $\\omega_2$: Stressed')\n",
    "ax.plot(xRange, gX, label = 'Discriminant function g(x)')\n",
    "\n",
    "minX = np.min(np.concatenate((x1, x2), axis=0))\n",
    "maxX = np.max(np.concatenate((x1, x2), axis=0))\n",
    "ax.set_xlim([minX-1, maxX+1])\n",
    "ax.set_xlabel(\"Indicator x\")\n",
    "ax.set_title(\"Training data points and the discriminant function g(x) modeling the classification\")\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sign of the discriminant function (its being positive or negative) \n",
    "# defines the decision rule for the classification\n",
    "\n",
    "# in gXSign we save the values xi where the sign of g(x) changes\n",
    "# and also what it changes into +1 (for becoming positive) and -1 for becoming \n",
    "# negative\n",
    "signChangesCounter = -1\n",
    "\n",
    "# Strategy to find the exact decision boundaries\n",
    "\n",
    "# To find the decision boundaries, we need to find the values of the indicator \n",
    "# x where the discriminant function equals 0. In the discrete space, we\n",
    "# can do this by finding the x so that g[xi] and g[xi+1] do not have the same \n",
    "# sign.\n",
    "\n",
    "# To determine the sign of the discriminant function for all values of x:\n",
    "# Assuming xi is a point where gX changes sign, we need to compare g[xi] and g[xi+1].\n",
    "# This way, if g[xi] < g[xi+1] the slope is ascending meaning gX[xj] < 0, \n",
    "# for all xj < xi down to another xi' where gX changes sign again and \n",
    "# gX[xk] > 0 up to another xi'' where gX changes sign again .\n",
    "\n",
    "# The same logic for the sign of gX applies when g[xi] > g[xi+1] (descending slope),\n",
    "# meaning\n",
    "# gX[xj] > 0, xj < xi and \n",
    "# gX[xj] < 0, xj > xi\n",
    "\n",
    "# gXSignList is a list saving all 2d lists [x, signIndicator] where x is the value \n",
    "# of the indicator x of the datapoint where the sign change occured and \n",
    "# signIndicator is +1 if the gX is ascending\n",
    "# beyond 0 (crosses the zero line) \n",
    "gXSignList = []\n",
    "for xi in range(len(gX)-1):\n",
    "    # if the next value of gX[xi] and gX[xi+1] are both positive or negative \n",
    "    # gX did not change sign (did not) \n",
    "    if gX[xi] * gX[xi + 1] <= 0:\n",
    "        if gX[xi] < gX[xi + 1]:\n",
    "            signChangesCounter = signChangesCounter + 1\n",
    "            gXSignList.append([xRange[xi], +1])\n",
    "        elif gX[xi] > gX[xi + 1]:\n",
    "            signChangesCounter = signChangesCounter + 1\n",
    "            gXSignList.append([xRange[xi], -1])\n",
    "\n",
    "\n",
    "# gXSignList conversion to a standard dimensions array\n",
    "gXSignArr = np.array(gXSignList)\n",
    "print(gXSignArr)\n",
    "\n",
    "\n",
    "# According to the discriminant function plotted above, the indicator x is \n",
    "# positive for the not stressed players and negative for the stressed ones. \n",
    "\n",
    "# The decision boundary lies approximately on x = -0.5 \n",
    "# (g(x) < 0 (stressed), for x < -0.5, g(x) > 0 (not stressed) for x > -0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B\n",
    "# 1. Baeysian estimation of parameter theta\n",
    "\n",
    "\n",
    "# Calculation of p(D|theta) across all values of theta (we can do this since p(x|theta) \n",
    "# is considered known for each class)\n",
    "# These are calculated in the exact same way as in the maximum likelihood estimation of theta\n",
    "# so their calculation will not be repeated here (they are the variables pDGivenTheta1, pDGivenTheta2).\n",
    "\n",
    "# It is the same for both classes\n",
    "aPrioriTheta = np.array(1/(10*pi)*1/(1+np.power(thetaRange/10, 2)))\n",
    "\n",
    "# For class 1\n",
    "# Discretisation of p(theta) so we can make calculations\n",
    "denominatorIntegral1 = 0\n",
    "denominatorIntegral2 = 0\n",
    "\n",
    "# Trapezoid rule for the integration \n",
    "for i in range(len(thetaRange)-1):\n",
    "    # The mean of two consecutive probability heights are used as the bases of the trapezoid bases  \n",
    "    denominatorIntegral1 = denominatorIntegral1 + thetaStep*float((pDGivenTheta1[i]+pDGivenTheta1[i+1])/2) \n",
    "    denominatorIntegral2 = denominatorIntegral2 + thetaStep*float((pDGivenTheta2[i]+pDGivenTheta2[i+1])/2) \n",
    "\n",
    "\n",
    "# p(theta), p(D|theta) and the denominator of the formula are now known so we can calculate\n",
    "# p(theta|D) and by graphing it we can derive the best estimation for theta for each class.\n",
    "pThetaGivenD1 = np.multiply(pDGivenTheta1, aPrioriTheta)/denominatorIntegral1 \n",
    "pThetaGivenD2 = np.multiply(pDGivenTheta2, aPrioriTheta)/denominatorIntegral2\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title(r'A posteriori pdf p($\\theta$$\\vert$$D_1$), p($\\theta$$\\vert$$D_2$) and a priori $p(\\theta)$')\n",
    "ax.set_xlabel(r'$\\theta$')\n",
    "\n",
    "ax.plot(thetaRange, pThetaGivenD1, label = r'p($\\theta$$\\vert$$D_1$)')\n",
    "ax.plot(thetaRange, pThetaGivenD2, label = r'p($\\theta$$\\vert$$D_2$)')\n",
    "ax.plot(thetaRange, aPrioriTheta, label = r'p($\\theta$)')\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax2 = plt.subplots()\n",
    "\n",
    "aPrioriTheta = np.array(1/(10*pi)*1/(1+np.power(thetaRange/10, 2)))\n",
    "\n",
    "\n",
    "ax2.set_title(r'A priori p($\\theta$), $p(D_1\\vert\\theta)$ and a posteriori p($\\theta$$\\vert$$D_1$)')\n",
    "ax2.plot(thetaRange, aPrioriTheta, label = r'p($\\theta$)')\n",
    "scalingFactor = 200000\n",
    "ax2.plot(thetaRange, pDGivenTheta1*scalingFactor, \\\n",
    "    label = r'$p(D_1\\vert\\theta)$ blown up ' + str(scalingFactor) + 'x')\n",
    "ax2.plot(thetaRange, pThetaGivenD1, label = r'p($\\theta$$\\vert$$D_1$)')\n",
    "ax2.set_xlabel(r'$\\theta$')\n",
    "\n",
    "\n",
    "\n",
    "# so that the legend is placed on the upper right corner of the graph\n",
    "ax2.legend(loc = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes: p(theta) is approximately constant for the theta\n",
    "# For the theta values where p(D|theta) is non zero (theta lying in [-5, 5])\n",
    "# p(theta) lies in (0.025, 0.032)   \n",
    "# together with the integral of the denominator, they scale p(D|theta) up and give \n",
    "# p(theta|D) as a result.\n",
    "\n",
    "\n",
    "maxPThetaGivenD1Mat = np.where(pThetaGivenD1 == np.max(pThetaGivenD1))\n",
    "maxPThetaGivenD1Index = maxPThetaGivenD1Mat[0][0]\n",
    "print('The best estimator for theta_1 is:', round(thetaRange[maxPThetaGivenD1Index], 2))\n",
    "\n",
    "maxPThetaGivenD2Mat = np.where(pThetaGivenD2 == np.max(pThetaGivenD2))\n",
    "maxPThetaGivenD2Index = maxPThetaGivenD2Mat[0][0]\n",
    "print('The best estimator for theta_2 is:', round(thetaRange[maxPThetaGivenD2Index], 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# p(x|theta,D), p(theta|D) are known (p(x|theta,D) = p(x|theta) for a specific class D)\n",
    "# for the so we can calculate p(x|D)\n",
    "# Calculation of p(x|D)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d13323f003d0e8bafb95ae33e43f500d3a0947472a7e395b07c317f965b540a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
