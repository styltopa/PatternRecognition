{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylianos Topalidis\n",
    "# AEM: 9613\n",
    "# email: styltopa@ece.auth.gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, tree\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# if the import below does not work please try opening a terminal and writing \n",
    "# pip install -U scikit-learn --user\n",
    "# this worked for me at least in vscode.\n",
    "# There is some discourse in the forum that it does not work in collab\n",
    "# see https://stackoverflow.com/questions/72246343/importerror-cannot-import-name-decisionboundarydisplay-from-sklearn-inspecti\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "\n",
    "# First attribute: sepal length (cm)\n",
    "# Second attribute: sepal width (cm)\n",
    "irisData = iris.data[:, 0:2]\n",
    "\n",
    "# Fields of iris data object\n",
    "# ['DESCR', 'data', 'data_module', 'feature_names', \\\n",
    "#  'filename', 'frame', 'target', 'target_names']\n",
    "\n",
    "# Percentage of the data for the training \n",
    "trainPercent = 0.5\n",
    "\n",
    "\n",
    "# Turn the target values into a set of all possible targets {0, 1, 2} \n",
    "# to exclude duplicates (multiple 0, 1 and 2)\n",
    "targetSet = set(iris.target)\n",
    "# Turn the set into a list and then into a numpy array\n",
    "# for convenience \n",
    "targetList = list(targetSet)\n",
    "targetArr = np.array(targetList) \n",
    "\n",
    "\n",
    "\n",
    "# Indexes for all the data samples (iterates over the data \n",
    "# for the different targets: setosa, versicolor, virginica) \n",
    "indsPerKind = []\n",
    "# Indexes for the training and testing data in the original dataset\n",
    "trainingInds = []\n",
    "testingInds = []\n",
    "\n",
    "\n",
    "# For each of the flower kinds\n",
    "for targetCount in range(len(targetArr)):\n",
    "    indexesArr = np.where(iris.target == targetCount)\n",
    "\n",
    "    # the first element of the list are the actual data \n",
    "    # and the second one is its data type \n",
    "    indsPerKind = list(indexesArr[0])\n",
    "\n",
    "    # number of training data derived from the training percentage selected\n",
    "    # per group identifier (0, 1, 2)\n",
    "    numOfTrainingDataPerIdentifier = round(trainPercent*len(indsPerKind))\n",
    "    numOfTestingDataPerIdentifier = len(indsPerKind) - numOfTrainingDataPerIdentifier\n",
    "\n",
    "    # concatenate the indices of the new target (identifier) training data \n",
    "    # with the indices of the old target training data.\n",
    "    trainingInds = trainingInds + indsPerKind[0:numOfTrainingDataPerIdentifier]\n",
    "    testingInds = testingInds + indsPerKind[numOfTrainingDataPerIdentifier:]\n",
    "    \n",
    "\n",
    "# list -> np.array\n",
    "trainingInds = np.array(trainingInds)\n",
    "testingInds = np.array(testingInds)\n",
    "\n",
    "# To avoid training the tree with batches of data of the same target,\n",
    "# as given (all setosa first, then all versicolor and finally all virginica),\n",
    "# we permute the training data\n",
    "np.random.seed(0)\n",
    "trainingIndsPerm =  np.random.permutation(trainingInds)\n",
    "\n",
    "# Training data and target values\n",
    "trainingArr = irisData[trainingIndsPerm]\n",
    "targetArrTraining = iris.target[trainingIndsPerm]\n",
    "\n",
    "# Testing data and target values\n",
    "testingArr = irisData[testingInds]\n",
    "targetArrTesting = iris.target[testingInds]\n",
    "\n",
    "\n",
    "\n",
    "print('Classification accuracy')\n",
    "# tree depths\n",
    "treeDepths = np.array([3, 4, 5])\n",
    "for depthCount in treeDepths:\n",
    "    # Classifier training\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depthCount)\n",
    "    clf = clf.fit(trainingArr, targetArrTraining)\n",
    "    \n",
    "    # Classifier predictions of the targets\n",
    "    targetArrPred = clf.predict(testingArr)\n",
    "\n",
    "\n",
    "    # number of correctly predicted target values\n",
    "    correctlyPredicted = 0\n",
    "\n",
    "    numOfTrainingData = len(targetSet)*numOfTrainingDataPerIdentifier\n",
    "\n",
    "\n",
    "    targetAndPred = np.stack((targetArrTesting, targetArrPred), axis=1) \n",
    "\n",
    "    for predCount in range(numOfTrainingData):\n",
    "        if targetArrTesting[predCount] == targetArrPred[predCount]: \n",
    "            # print(targetAndPred[predCount])\n",
    "            correctlyPredicted = correctlyPredicted + 1\n",
    "        # else:\n",
    "            # print(targetAndPred[predCount])\n",
    "\n",
    "\n",
    "    accuracy = correctlyPredicted/numOfTrainingData\n",
    "    # print(correctlyPredicted)\n",
    "    # print(numOfTrainingData)\n",
    "    print('For decision tree depth = ', depthCount, ': ', round(accuracy*100, 2), '%')\n",
    "    if depthCount == treeDepths[0]:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "    if maxAcc < accuracy:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "\n",
    "print('\\nMax accuracy classifier was the one with depth = ', maxAccClf.tree_.max_depth, 'and accuracy: ', round(100*maxAcc, 2), '%')\n",
    "\n",
    "\n",
    "\n",
    "# do what the cell below does but in a way that you understand it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Find the decision bounds from the classifier, make a function to get it from the \n",
    "# branches of the tree\n",
    "# 2) Plot the space partition and their corresponding prdeiction of the target variable.\n",
    "# 3) Plot the points \n",
    "\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter()\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "iris = load_iris()\n",
    "feature_1, feature_2 = np.meshgrid(\n",
    "    np.linspace(iris.data[:, 0].min(), iris.data[:, 0].max()),\n",
    "    np.linspace(iris.data[:, 1].min(), iris.data[:, 1].max())\n",
    ")\n",
    "grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T\n",
    "tree = DecisionTreeClassifier().fit(iris.data[:, :2], iris.target)\n",
    "y_pred = np.reshape(tree.predict(grid), feature_1.shape)\n",
    "display = DecisionBoundaryDisplay(\n",
    "    xx0=feature_1, xx1=feature_2, response=y_pred\n",
    ")\n",
    "display.plot()\n",
    "\n",
    "display.ax_.scatter(\n",
    "    iris.data[:, 0], iris.data[:, 1], c=iris.target, edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57a2b867923f2cc7a1df74fe767d6b0c98820aad4964c16add11e9af3ce14a54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
