{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stylianos Topalidis\n",
    "# AEM: 9613\n",
    "# email: styltopa@ece.auth.gr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, tree\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# if the import below does not work please try opening a terminal and writing \n",
    "# pip install -U scikit-learn --user\n",
    "# this worked for me at least in vscode.\n",
    "# There is some discourse in the forum that it does not work in collab\n",
    "# see https://stackoverflow.com/questions/72246343/importerror-cannot-import-name-decisionboundarydisplay-from-sklearn-inspecti\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "import random \n",
    "import math\n",
    "from IPython.display import HTML, display\n",
    "import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "----------------------------------\n",
      "Max accuracy classifier is the one with depth =  4 and accuracy:  80.0 %\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  Decision Tree depth</th><th style=\"text-align: right;\">  Accuracy (%)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">                    1</td><td style=\"text-align: right;\">          64  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">                    2</td><td style=\"text-align: right;\">          68  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">                    3</td><td style=\"text-align: right;\">          69.3</td></tr>\n",
       "<tr><td style=\"text-align: right;\">                    4</td><td style=\"text-align: right;\">          80  </td></tr>\n",
       "<tr><td style=\"text-align: right;\">                    5</td><td style=\"text-align: right;\">          80  </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part A\n",
    "\n",
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "\n",
    "# First attribute: sepal length (cm)\n",
    "# Second attribute: sepal width (cm)\n",
    "irisData = iris.data[:, 0:2]\n",
    "\n",
    "# Fields of iris data object\n",
    "# ['DESCR', 'data', 'data_module', 'feature_names', \\\n",
    "#  'filename', 'frame', 'target', 'target_names']\n",
    "\n",
    "# Percentage of the data for the training \n",
    "trainPercent = 0.5\n",
    "\n",
    "\n",
    "# Turn the target values into a set of all possible targets {0, 1, 2} \n",
    "# to exclude duplicates (multiple 0, 1 and 2)\n",
    "# Turn the set into a list and then into a numpy array\n",
    "# for convenience \n",
    "targetArr = np.array(list(set(iris.target)))\n",
    "\n",
    "\n",
    "\n",
    "# Indexes for all the data samples (iterates over the data \n",
    "# for the different targets: setosa, versicolor, virginica) \n",
    "indsPerKind = []\n",
    "# Indexes for the training and testing data in the original dataset\n",
    "trainingInds = []\n",
    "testingInds = []\n",
    "\n",
    "\n",
    "# For each of the flower kinds\n",
    "for targetCount in range(len(targetArr)):\n",
    "    indexesArr = np.where(iris.target == targetCount)\n",
    "\n",
    "    # the first element of the list are the actual data \n",
    "    # and the second one is its data type \n",
    "    indsPerKind = list(indexesArr[0])\n",
    "\n",
    "    # number of training data derived from the training percentage selected\n",
    "    # per group identifier (0, 1, 2)\n",
    "    numOfTrainingDataPerIdentifier = round(trainPercent*len(indsPerKind))\n",
    "    numOfTestingDataPerIdentifier = len(indsPerKind) - numOfTrainingDataPerIdentifier\n",
    "\n",
    "    # concatenate the indices of the new target (identifier) training data \n",
    "    # with the indices of the old target training data.\n",
    "    trainingInds = trainingInds + indsPerKind[0:numOfTrainingDataPerIdentifier]\n",
    "    testingInds = testingInds + indsPerKind[numOfTrainingDataPerIdentifier:]\n",
    "    \n",
    "\n",
    "# list -> np.array\n",
    "trainingInds = np.array(trainingInds)\n",
    "testingInds = np.array(testingInds)\n",
    "\n",
    "# To avoid training the tree with batches of data of the same target,\n",
    "# as given (all setosa first, then all versicolor and finally all virginica),\n",
    "# we permute the training data\n",
    "np.random.seed(0)\n",
    "trainingIndsPerm =  np.random.permutation(trainingInds)\n",
    "\n",
    "# Training data and target values\n",
    "trainingArr = irisData[trainingIndsPerm]\n",
    "targetArrTraining = iris.target[trainingIndsPerm]\n",
    "\n",
    "# Testing data and target values\n",
    "testingArr = irisData[testingInds]\n",
    "targetArrTesting = iris.target[testingInds]\n",
    "\n",
    "# List with the accuracies of all classifiers per depth\n",
    "accList = list()\n",
    "\n",
    "# A.1\n",
    "print('Decision Tree Classifier')\n",
    "\n",
    "# tree depths\n",
    "treeDepths = np.array([1, 2, 3, 4, 5])\n",
    "for depthCount, depth in enumerate(treeDepths):\n",
    "    # Classifier training\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(trainingArr, targetArrTraining)\n",
    "    \n",
    "    # Classifier predictions of the targets\n",
    "    targetArrPred = clf.predict(testingArr)\n",
    "\n",
    "\n",
    "    # number of correctly predicted target values\n",
    "    correctlyPredicted = 0\n",
    "\n",
    "    numOfTrainingData = len(targetArr)*numOfTrainingDataPerIdentifier\n",
    "\n",
    "\n",
    "    targetAndPred = np.stack((targetArrTesting, targetArrPred), axis=1) \n",
    "\n",
    "    for predCount in range(numOfTrainingData):\n",
    "        if targetArrTesting[predCount] == targetArrPred[predCount]: \n",
    "            correctlyPredicted = correctlyPredicted + 1\n",
    "\n",
    "    accuracy = correctlyPredicted/numOfTrainingData\n",
    "    accList.append([str(depth), str(round(100*accuracy, 1))])\n",
    "    # Print the accuracy for every tree depth\n",
    "    if depth == treeDepths[0]:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "    if maxAcc < accuracy:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "\n",
    "print('----------------------------------'\n",
    "    '\\nMax accuracy classifier is the one with depth = ', maxAccClf.tree_.max_depth, \\\n",
    "    'and accuracy: ', round(100*maxAcc, 2), '%')\n",
    "\n",
    "\n",
    "\n",
    "table = tabulate.tabulate(accList, tablefmt='html', headers=[\"Decision Tree depth\", \"Accuracy (%)\"])\n",
    "display(HTML(table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # A.2\n",
    "# # Display the decision boundaries\n",
    "# decisionBoundDisp = DecisionBoundaryDisplay.from_estimator(\n",
    "#     maxAccClf, trainingArr,  cmap=plt.cm.cividis, response_method=\"predict\",\n",
    "#     xlabel=iris.feature_names[0], ylabel=iris.feature_names[1],\n",
    "#     plot_method= 'contourf'\n",
    "# )\n",
    "\n",
    "# c  = ['blue', 'grey', 'yellow']\n",
    "\n",
    "# for i, t in enumerate(targetArr):\n",
    "#     targetInds = np.where(targetArrTesting == t)\n",
    "#     plt.scatter(\n",
    "#         testingArr[targetInds, 0], testingArr[targetInds, 1], color=c[i], edgecolor=\"black\", label = iris.target_names[i]\n",
    "#     )\n",
    "\n",
    "# decisionBoundDisp.ax_.set_title('Decision boundaries of the classifier\\nDecision tree depth = ' \\\n",
    "#     + str(maxAccClf.tree_.max_depth))\n",
    "\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "------------------------------------\n"
     ]
    },
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [24], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# Classifier training\u001b[39;00m\n\u001b[0;32m     24\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators\u001b[39m=\u001b[39mB, max_depth\u001b[39m=\u001b[39mdepthCount, bootstrap\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_samples\u001b[39m=\u001b[39mbootSamNumOfElem)\n\u001b[1;32m---> 25\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39;49mfit(trainingArr, targetArrTraining)\n\u001b[0;32m     27\u001b[0m \u001b[39m# Classifier predictions of the targets\u001b[39;00m\n\u001b[0;32m     28\u001b[0m targetArrPred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(testingArr)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\ensemble\\_forest.py:341\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    315\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    316\u001b[0m \u001b[39m    Build a forest of trees from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_params()\n\u001b[0;32m    343\u001b[0m     \u001b[39m# Validate or convert input data\u001b[39;00m\n\u001b[0;32m    344\u001b[0m     \u001b[39mif\u001b[39;00m issparse(y):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\base.py:570\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_params\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    563\u001b[0m     \u001b[39m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \n\u001b[0;32m    565\u001b[0m \u001b[39m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    569\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     validate_parameter_constraints(\n\u001b[0;32m    571\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parameter_constraints,\n\u001b[0;32m    572\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_params(deep\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m    573\u001b[0m         caller_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m,\n\u001b[0;32m    574\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:97\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     constraints_str \u001b[39m=\u001b[39m (\n\u001b[0;32m     93\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39mstr\u001b[39m(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m constraints[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]])\u001b[39m}\u001b[39;00m\u001b[39m or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     94\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[1;32m---> 97\u001b[0m \u001b[39mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     98\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m{\u001b[39;00mparam_name\u001b[39m!r}\u001b[39;00m\u001b[39m parameter of \u001b[39m\u001b[39m{\u001b[39;00mcaller_name\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mconstraints_str\u001b[39m}\u001b[39;00m\u001b[39m. Got \u001b[39m\u001b[39m{\u001b[39;00mparam_val\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'max_depth' parameter of RandomForestClassifier must be an int in the range [1, inf) or None. Got 0 instead."
     ]
    }
   ],
   "source": [
    "# Part B\n",
    "\n",
    "# Number of bootstrap samples and number of trees in the random forest classifier\n",
    "B = 100\n",
    "# Percentage of the original training data in the bootstrap samples\n",
    "gamma = 0.5\n",
    "\n",
    "numOfTrainingData = len(targetArr)*numOfTrainingDataPerIdentifier\n",
    "\n",
    "# Number of elements per bootstrap sample\n",
    "bootSamNumOfElem = round(gamma*numOfTrainingData)\n",
    "\n",
    "# List with the accuracies of all classifiers per depth\n",
    "accList = list()\n",
    "\n",
    "rnd = random.random()\n",
    "\n",
    "print('Random Forest Classifier\\n------------------------------------')\n",
    "# Forest tree depths\n",
    "treeDepths = np.array([1, 2, 3, 4, 5])\n",
    "for depthCount, depth in enumerate(treeDepths):\n",
    "    random.seed(rnd)\n",
    "    # Classifier training\n",
    "    clf = RandomForestClassifier(n_estimators=B, max_depth=depth, bootstrap=True, max_samples=bootSamNumOfElem)\n",
    "    clf = clf.fit(trainingArr, targetArrTraining)\n",
    "\n",
    "    # Classifier predictions of the targets\n",
    "    targetArrPred = clf.predict(testingArr)\n",
    "\n",
    "    # Accuracy \n",
    "\n",
    "    # Number of correctly predicted samples\n",
    "    correctlyPredicted = 0\n",
    "    # contains both the real and the predicted target values\n",
    "    targetAndPred = np.stack((targetArrTesting, targetArrPred), axis=1) \n",
    "    # for every sample prediction\n",
    "    for predCount in range(numOfTrainingData):\n",
    "        if targetArrTesting[predCount] == targetArrPred[predCount]: \n",
    "            correctlyPredicted = correctlyPredicted + 1\n",
    "       \n",
    "    accuracy = correctlyPredicted/numOfTrainingData\n",
    "    accList.append([str(depth), str(round(100*accuracy, 1))])\n",
    "    # print('For decision tree depth = ', depthCount, ': ', round(accuracy*100, 2), '%')\n",
    "    if depthCount == treeDepths[0]:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "        maxAccDepth = depthCount\n",
    "    if maxAcc < accuracy:\n",
    "        maxAccClf = clf\n",
    "        maxAcc = accuracy\n",
    "        maxAccDepth = depthCount\n",
    "\n",
    "print('Max accuracy classifier is the one with decision tree depth = ', str(maxAccDepth), \\\n",
    "    'and accuracy: ', round(100*maxAcc, 2), '%')\n",
    "\n",
    "\n",
    "\n",
    "table = tabulate.tabulate(accList, tablefmt='html', headers=[\"Decision Tree depth\", \"Accuracy (%)\"])\n",
    "display(HTML(table))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(15, 6), dpi=80)\n",
    "\n",
    "# Set common labels\n",
    "fig.text(0.5, 0.04, iris.feature_names[0], ha='center', va='center')\n",
    "fig.text(0.06, 0.5, iris.feature_names[1], ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Decision boundaries of the forests trained with different gamma \n",
    "# (percentage of the original training data)\n",
    "gammaArr = [0.2, 0.5, 0.8]\n",
    "\n",
    "for gammaCount, gammaVal in enumerate(gammaArr):\n",
    "    \n",
    "    # different percentage (gamma) of the original training data  is used each time\n",
    "    bootSamNumOfElem = round(gammaVal*numOfTrainingData)\n",
    "\n",
    "    # to get the same classifier as before\n",
    "    random.seed(rnd)\n",
    "    # Training for the different gamma values for the maxDepth found before\n",
    "    clf = RandomForestClassifier(n_estimators=B, max_depth=maxAccDepth, bootstrap=True, max_samples=bootSamNumOfElem)\n",
    "    clf = clf.fit(trainingArr, targetArrTraining)\n",
    "\n",
    "    # Classifier predictions of the targets\n",
    "    targetArrPred = clf.predict(testingArr)\n",
    "\n",
    "    # Accuracy \n",
    "\n",
    "    # Number of correctly predicted samples\n",
    "    correctlyPredicted = 0\n",
    "    # contains both the real and the predicted target values\n",
    "    targetAndPred = np.stack((targetArrTesting, targetArrPred), axis=1) \n",
    "    # for every sample prediction\n",
    "    for predCount in range(numOfTrainingData):\n",
    "        if targetArrTesting[predCount] == targetArrPred[predCount]: \n",
    "            correctlyPredicted = correctlyPredicted + 1\n",
    "       \n",
    "    accuracy = correctlyPredicted/numOfTrainingData\n",
    "\n",
    "    # Plot the corresponding subplot\n",
    "    ax = plt.subplot(1, len(gammaArr), gammaCount+1)        \n",
    "    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=7.5)\n",
    "    decisionBoundDisp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf, trainingArr,  cmap=plt.cm.cividis, response_method=\"predict\",\n",
    "        ax = ax,\n",
    "        xlabel=r'$\\gamma$ ='+ str(100*gammaVal)+ '%\\naccuracy='+ str(round(100*accuracy, 2))+ '%',\n",
    "        plot_method= 'contourf'\n",
    "    )\n",
    "\n",
    "    c  = ['blue', 'grey', 'yellow']\n",
    "\n",
    "    for counter, target in enumerate(targetArr):\n",
    "        targetInds = np.where(targetArrTesting == target)\n",
    "        plt.scatter(\n",
    "            testingArr[targetInds, 0], testingArr[targetInds, 1], color=c[counter], edgecolor=\"black\", label = iris.target_names[counter]\n",
    "        )\n",
    "\n",
    "\n",
    "plt.suptitle('Decision boundaries of the classifier\\nDecision trees depth = ' \\\n",
    "        + str(maxAccDepth))\n",
    "plt.legend(loc='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the tree depths giving the max accuracy \n",
    "\n",
    "# Number of bootstrap samples and number of trees in the random forest classifier\n",
    "B = 100\n",
    "# Percentage of the original training data in the bootstrap samples\n",
    "gamma = 0.5\n",
    "\n",
    "numOfTrainingData = len(targetArr)*numOfTrainingDataPerIdentifier\n",
    "\n",
    "# Number of elements per bootstrap sample\n",
    "bootSamNumOfElem = round(gamma*numOfTrainingData)\n",
    "maxAccDepthList = []\n",
    "\n",
    "for j in range(1, 20):\n",
    "    rnd = random.random()\n",
    "    if j !=1:\n",
    "        maxAccDepthList.append(maxAccDepth)\n",
    "    # print('Classification accuracy\\n------------------------------------')\n",
    "    # Forest tree depths\n",
    "    treeDepths = np.array([1, 2, 3, 4, 5])\n",
    "    for depthCount in treeDepths:\n",
    "        random.seed(rnd)\n",
    "        # Classifier training\n",
    "        clf = RandomForestClassifier(n_estimators=B, max_depth=depthCount, bootstrap=True, max_samples=bootSamNumOfElem)\n",
    "        clf = clf.fit(trainingArr, targetArrTraining)\n",
    "\n",
    "        # Classifier predictions of the targets\n",
    "        targetArrPred = clf.predict(testingArr)\n",
    "\n",
    "        # Accuracy \n",
    "\n",
    "        # Number of correctly predicted samples\n",
    "        correctlyPredicted = 0\n",
    "        # contains both the real and the predicted target values\n",
    "        targetAndPred = np.stack((targetArrTesting, targetArrPred), axis=1) \n",
    "        # for every sample prediction\n",
    "        for predCount in range(numOfTrainingData):\n",
    "            if targetArrTesting[predCount] == targetArrPred[predCount]: \n",
    "                correctlyPredicted = correctlyPredicted + 1\n",
    "        \n",
    "        accuracy = correctlyPredicted/numOfTrainingData\n",
    "        # print('For decision tree depth = ', depthCount, ': ', round(accuracy*100, 2), '%')\n",
    "        if depthCount == treeDepths[0]:\n",
    "            maxAccClf = clf\n",
    "            maxAcc = accuracy\n",
    "            maxAccDepth = depthCount\n",
    "        if maxAcc < accuracy:\n",
    "            maxAccClf = clf\n",
    "            maxAcc = accuracy\n",
    "            maxAccDepth = depthCount\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.hist(np.array(maxAccDepthList))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57a2b867923f2cc7a1df74fe767d6b0c98820aad4964c16add11e9af3ce14a54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
